#!/usr/bin/env python3

#
# This plugin is designed as a nagios compatible check plugin to use with
# Icinga 2 and others
#

import argparse
import sys
from datetime import datetime, timedelta
from urllib.parse import urljoin

import requests

proxies = {
  "http": None,
  "https": None,
}

class PrometheusAPI:
    def __init__(self, endpoint='http://127.0.0.1:9090/'):
        """
        :param endpoint: address of
        """
        self.endpoint = endpoint

    def _to_timestamp(self, input, base=None):
        """
        Convert string input to UNIX timestamp for Prometheus

        :param input:
        :param base:
        :return:
        """
        if type(input) == datetime:
            return input.timestamp()
        if input == 'now':
            return datetime.utcnow().timestamp()
        if type(input) in [int, float]:
            if input > 0:
                return input
            if input == 0:      # return now
                return datetime.utcnow().timestamp()
            if input < 0:
                base = self._to_timestamp(base)
                return base + input
        assert type(input) == float

    def query(self, query='prometheus_build_info'):
        return self._get(
            uri='/api/v1/query',
            params=dict(
                query=query
            )
        )
    
    def scalar(self, query):
        data = self.query(query)
        return(float(data['data']['result'][0]['value'][1]))

    def vector(self, query):
        data = self.query(query)
        retv = []
        for item in data['data']['result']:
            key = item['metric']
            val = item['value']
            retv.append( (key, float(val[1])))
        return retv

    def _get(self, uri, params, method='GET'):
        url = urljoin(self.endpoint, uri)
        assert method == 'GET'
        result = requests.get(
            url=url,
            params=params,
            proxies=proxies,
        )
        return result.json()

prom = PrometheusAPI()

def main():
    parser = argparse.ArgumentParser('Check scraper is up')
    parser.add_argument('--instance', required=True)
    parser.add_argument('--tags', required=False, type=str)
#    parser.add_argument('--tags', default=1, type=int)
    parser.add_argument('--warning-timeout', type=int, default=5)
    parser.add_argument('--critical-timeout', type=int, default=30)
    args = parser.parse_args()

    instance = args.instance
    if args.tags:
        check_query = 'up{instance="%s",%s}' % (args.instance, args.tags)
        duration_query = 'scrape_duration_seconds{instance="%s",%s}' % (args.instance, args.tags)
        duration_query = 'scrape_duration_seconds{instance="%s",%s}' % (args.instance, args.tags)
        samples_query = 'scrape_samples_scraped{instance="%s",%s}' % (args.instance, args.tags)
    else:
        check_query = 'up{instance="%s"}' % args.instance
        duration_query = 'scrape_duration_seconds{instance="%s"}' % (args.instance)
        samples_query = 'scrape_samples_scraped{instance="%s"}' % (args.instance)

    result = int(prom.scalar(check_query))
    duration = float(prom.scalar(duration_query))
    samples = int(prom.scalar(samples_query))
    #
    if result == 0:
        print("CRITICAL - unable to scrape instance %s" % args.instance)
        return 2 # CRITICAL
    if duration > args.critical_timeout:
        status, message = 2, "CRITICAL - ".format(duration)
    elif duration > args.warning_timeout:
        status, message = 1, "WARNING - "
    else:
        status, message = 0, ""

    message = message + "scraping took {:.1f}s".format(duration)
    print(message, end='|')
    print('duration={:3f}s;{};{};0;'.format(duration, args.warning_timeout, args.critical_timeout), end=' ')
    print('samples={:d}'.format(samples))
    
    raise SystemExit(status)

if __name__ == '__main__':
    try:
        sys.exit(main())
    except Exception as e:
        if sys.stdout.isatty:
            raise
        print('Error - %s' % str(e))
        sys.exit(3)
    finally:
        pass
